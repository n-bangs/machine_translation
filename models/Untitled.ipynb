{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import dill as pickle\n",
    "from nltk.translate.phrase_based import phrase_extraction,extract\n",
    "from nltk.translate import AlignedSent\n",
    "from nltk.translate import PhraseTable\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "from cltk.tokenize.word import WordTokenizer\n",
    "from cltk.stem.lemma import LemmaReplacer\n",
    "from nltk.translate import AlignedSent, Alignment, IBMModel1, IBMModel2\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.translate.ibm_model import AlignmentInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat_tokenizer = WordTokenizer('latin').tokenize\n",
    "eng_tokenizer = wordpunct_tokenize\n",
    "lem = LemmaReplacer('latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../pkls/lat_ibm_model_2_bitext.pk', 'rb') as fin:\n",
    "    lbitext = pkl.load(fin)\n",
    "\n",
    "with open('../pkls/eng_ibm_model_2_bitext.pk', 'rb') as fin:\n",
    "    ebitext = pkl.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for b in range(len(ebitext)):\n",
    "    if ebitext[b].mots[-1] != 'NULL':\n",
    "        ebitext[b].mots.append('NULL')\n",
    "    if ebitext[b].words[-1] != 'NULL':\n",
    "        ebitext[b].words.append('NULL')\n",
    "    lens = [len(ebitext[b].words),len(ebitext[b].mots)]\n",
    "\n",
    "    alin = [list(tup) for tup in ebitext[b].alignment]\n",
    "\n",
    "    for i,a in enumerate(alin):\n",
    "        if None in a:\n",
    "            alin[i][alin[i].index(None)] = lens[a.index(None)]-1\n",
    "\n",
    "    alin = [tuple(tup) for tup in alin]\n",
    "\n",
    "    ebitext[b].alignment = Alignment(alin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for b in range(len(lbitext)):\n",
    "    if lbitext[b].mots[-1] != 'NULL':\n",
    "        lbitext[b].mots.append('NULL')\n",
    "    if lbitext[b].words[-1] != 'NULL':\n",
    "        lbitext[b].words.append('NULL')\n",
    "    lens = [len(lbitext[b].words),len(lbitext[b].mots)]\n",
    "\n",
    "    alin = [list(tup) for tup in lbitext[b].alignment]\n",
    "\n",
    "    for i,a in enumerate(alin):\n",
    "        if None in a:\n",
    "            alin[i][alin[i].index(None)] = lens[a.index(None)]-1\n",
    "\n",
    "    alin = [tuple(tup) for tup in alin]\n",
    "\n",
    "    lbitext[b].alignment = Alignment(alin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skip = [7829, 9778,11352]\n",
    "\n",
    "ephrases = defaultdict(lambda: [0,defaultdict(int)])\n",
    "\n",
    "for b in range(len(ebitext)): \n",
    "    if b in skip:\n",
    "        continue\n",
    "    pe = phrase_extraction(' '.join(ebitext[b].words), ' '.join(ebitext[b].mots), ebitext[b].alignment,max_phrase_length=4)\n",
    "    pe = list(pe)\n",
    "    for phrase in pe:\n",
    "        english_tokens = eng_tokenizer(phrase[2])\n",
    "        lat_tokens = lat_tokenizer(phrase[3])\n",
    "        \n",
    "        if len(english_tokens) < 5 and len(lat_tokens) < 5:\n",
    "            ephrases[tuple(english_tokens)][1][tuple(lat_tokens)] += 1\n",
    "            ephrases[tuple(english_tokens)][0] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#skip = [7829, 9778,11352]\n",
    "\n",
    "lphrases = defaultdict(lambda: [0,defaultdict(int)])\n",
    "\n",
    "for b in range(len(lbitext)): \n",
    "    if b in skip:\n",
    "        continue\n",
    "    pe = phrase_extraction(' '.join(lbitext[b].words), ' '.join(lbitext[b].mots), lbitext[b].alignment,max_phrase_length=4)    \n",
    "    pe = list(pe)\n",
    "    for phrase in pe:\n",
    "        english_tokens = eng_tokenizer(phrase[3])\n",
    "        lat_tokens = lat_tokenizer(phrase[2])\n",
    "        \n",
    "        if len(english_tokens) < 5 and len(lat_tokens) < 5:\n",
    "            lphrases[tuple(lat_tokens)][1][tuple(english_tokens)] += 1\n",
    "            lphrases[tuple(lat_tokens)][0] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phrases = defaultdict(lambda: [0,defaultdict(int)])\n",
    "untranslated = dict()\n",
    "\n",
    "for phrase in list(ephrases.keys()):\n",
    "    added = False\n",
    "    for trg_phrase in ephrases[phrase][1]:\n",
    "        if lphrases[trg_phrase][0] != 0:\n",
    "            for sub_phrase in lphrases[trg_phrase][1]:\n",
    "                if sub_phrase == phrase:\n",
    "                    phrases[phrase][1][trg_phrase] += ephrases[phrase][1][trg_phrase]\n",
    "                    phrases[phrase][0] += ephrases[phrase][1][trg_phrase]\n",
    "                    added = True\n",
    "    if not added:\n",
    "        untranslated[phrase] = ephrases[phrase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, defaultdict(int, {('vivit',): 2})]"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases[('lives',)]#[('NULL'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in untranslated:  # while there are still untranslated phrases\n",
    "    maximum = 0\n",
    "    for possible_translation in untranslated[k][1]:\n",
    "        if untranslated[k][1][possible_translation] > maximum:\n",
    "            maximum = untranslated[k][1][possible_translation]\n",
    "            translation = possible_translation\n",
    "    phrases[k][0] = maximum\n",
    "    phrases[k][1][translation] = maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " defaultdict(int,\n",
       "             {('clementia', 'caesaris'): 1,\n",
       "              ('clementia', 'caesaris', 'reditum'): 1,\n",
       "              ('clementia', 'caesaris', 'reditum', 'patere'): 1})]"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untranslated[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2259,\n",
       " defaultdict(int,\n",
       "             {('-', 'ne'): 76,\n",
       "              ('-', 'que'): 152,\n",
       "              ('-', 'que', 'NULL'): 2,\n",
       "              ('-', 'que', 'eo'): 1,\n",
       "              ('-', 'que', 'id'): 1,\n",
       "              ('-', 'que', 'in'): 3,\n",
       "              ('a',): 35,\n",
       "              ('ab',): 18,\n",
       "              ('ac',): 34,\n",
       "              ('ad',): 76,\n",
       "              ('atque',): 35,\n",
       "              ('autem',): 69,\n",
       "              ('cum',): 37,\n",
       "              ('ea',): 15,\n",
       "              ('eius',): 18,\n",
       "              ('eo',): 61,\n",
       "              ('esse',): 7,\n",
       "              ('est',): 233,\n",
       "              ('est', 'NULL'): 58,\n",
       "              ('et',): 215,\n",
       "              ('et', 'in'): 1,\n",
       "              ('ex',): 128,\n",
       "              ('ex', 'eo'): 2,\n",
       "              ('ex', 'quo'): 5,\n",
       "              ('his',): 24,\n",
       "              ('id',): 16,\n",
       "              ('id', '-', 'que'): 5,\n",
       "              ('in',): 264,\n",
       "              ('inter',): 44,\n",
       "              ('modo',): 18,\n",
       "              ('non',): 18,\n",
       "              ('per',): 42,\n",
       "              ('qua',): 6,\n",
       "              ('quae',): 71,\n",
       "              ('quae', 'ad'): 2,\n",
       "              ('quae', 'in'): 4,\n",
       "              ('quae', 'per'): 2,\n",
       "              ('quam',): 23,\n",
       "              ('qui',): 35,\n",
       "              ('qui', 'in'): 3,\n",
       "              ('quo',): 64,\n",
       "              ('quod',): 75,\n",
       "              ('se',): 37,\n",
       "              ('si',): 16,\n",
       "              ('sunt',): 89,\n",
       "              ('sunt', 'NULL'): 16,\n",
       "              ('sunt', 'in'): 1,\n",
       "              ('sunt', 'qui'): 1,\n",
       "              ('ut',): 13,\n",
       "              ('ut', 'ad'): 2,\n",
       "              ('vero',): 86})]"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases[('the',)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phrase_table = PhraseTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in phrases:\n",
    "    for t in phrases[k][1]:\n",
    "        phrase_table.add(k,t,log(phrases[k][1][t]/phrases[k][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhraseTableEntry(trg_phrase=('domum',), log_prob=-0.20763936477824449),\n",
       " PhraseTableEntry(trg_phrase=('domus',), log_prob=-1.6739764335716716)]"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_table.translations_for(('house',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Users/nickybangs/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2880\u001b[0m                 \u001b[0;31m#rprint('Running code', repr(code_obj)) # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2881\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2882\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-481-5da7046b1cec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../pkls/latin_lang_model.pk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlang_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/nickybangs/anaconda3/lib/python3.5/site-packages/dill/dill.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0mpik\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_main\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_main_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpik\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_main_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# point obj class to main\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nickybangs/anaconda3/lib/python3.5/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1038\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nickybangs/anaconda3/lib/python3.5/pickle.py\u001b[0m in \u001b[0;36mload_long_binget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_long_binget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1421\u001b[0;31m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<I'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nickybangs/anaconda3/lib/python3.5/pickle.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Users/nickybangs/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2895\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('../pkls/latin_lang_model.pk', 'rb') as fin:\n",
    "    lang_model = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.translate.stack_decoder import StackDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def language_prob(phrase):\n",
    "    phrase = ['**','**'] + phrase + ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "language_model = type('',(object,),{'probability_change': lambda self, context, phrase: language_prob(phrase), 'probability': lambda self, phrase: language_prob(phrase)})()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "StackDecoder()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
