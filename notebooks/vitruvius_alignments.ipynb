{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from cltk.stem.lemma import LemmaReplacer\n",
    "from cltk.tokenize.word import WordTokenizer\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from cltk.tokenize.sentence import TokenizeSentence\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import bs4\n",
    "\n",
    "def make_list(soup):\n",
    "    l = []\n",
    "    for n in soup:\n",
    "        try:\n",
    "            l.append(int(n['n']))\n",
    "        except:\n",
    "            l.append(-1)  \n",
    "    return remove_duplicates(l)\n",
    "\n",
    "\n",
    "def remove_duplicates(l):\n",
    "    i = 0\n",
    "    while i+1 < len(l):\n",
    "        if l[i] == l[i+1]:\n",
    "            l[i+1] += 1\n",
    "        if l[i] > l[i+1] and l[i+1] != -1:\n",
    "            l[i] = l[i+1]-1\n",
    "        i += 1\n",
    "    return l\n",
    "\n",
    "def match(large,small):\n",
    "    l = make_list(large)\n",
    "    s = make_list(small)\n",
    "    li = 0\n",
    "    si = 0\n",
    "    groups = []\n",
    "    #print(l,s)\n",
    "    while si < len(s) and li < len(l):\n",
    "        if s[si] == -1:\n",
    "            si += 1\n",
    "            continue\n",
    "        if l[li] == -1:\n",
    "            li += 1\n",
    "            continue\n",
    "        lgroup = []\n",
    "        sgroup = []\n",
    "        if l[li] == s[si]:\n",
    "            lgroup.append(li)\n",
    "            sgroup.append(si)\n",
    "              \n",
    "        if si+1 < len(s) and li+1 < len(l): \n",
    "            if s[si+1] == -1:\n",
    "                si += 1\n",
    "            \n",
    "            if l[li+1] == -1:\n",
    "                li += 1\n",
    "            \n",
    "            \n",
    "            if l[li+1] != s[si+1]:\n",
    "                while l[li+1] != s[si+1]:\n",
    "                    if si+1 < len(s) and li+1 < len(l):\n",
    "                        if l[li+1] > s[si+1]:\n",
    "                            sgroup.append(si+1)\n",
    "                            si += 1\n",
    "                            if s[si] == -1:\n",
    "                                if si+1 < len(s):\n",
    "                                    si += 1\n",
    "                                else:\n",
    "                                    pass\n",
    "                        else:\n",
    "                            lgroup.append(li+1)\n",
    "                            li += 1\n",
    "                            if l[li] == -1:\n",
    "                                if li+1 < len(l):\n",
    "                                    li += 1\n",
    "                                else:\n",
    "                                    pass\n",
    "                    else:\n",
    "                        break\n",
    "                si += 1\n",
    "                li += 1\n",
    "                groups.append([sgroup,lgroup])\n",
    "            else:\n",
    "                si += 1\n",
    "                li += 1\n",
    "                groups.append([sgroup,lgroup]) \n",
    "        else:\n",
    "            break        \n",
    "    \n",
    "    groups.append([sgroup,lgroup])\n",
    "    return groups\n",
    "        \n",
    "\n",
    "def align_soups(m,small,large):\n",
    "    s_alignments = []\n",
    "    l_alignments = []\n",
    "    for g in m:\n",
    "        s = []\n",
    "        l = []\n",
    "        for i in g[0]:\n",
    "            s.append(small[i])\n",
    "        for i in g[1]:\n",
    "            l.append(large[i])\n",
    "        s_alignments.append(s)\n",
    "        l_alignments.append(l)   \n",
    "    return s_alignments,l_alignments\n",
    "\n",
    "\n",
    "def get_pairs(latin_soup, eng_soup, tag, typename, typos):\n",
    "    \"\"\" Given two soups, returns soups of equal size, with each element corresponding to the same\n",
    "        element in the other soup.\n",
    "        Lists may contain further lists of soups which are aligned with one another, they are combined into one list\n",
    "        in the first step of this function.\n",
    "    \"\"\"\n",
    "    lat_sect,eng_sect = [], []\n",
    "    \n",
    "    for i in range(len(latin_soup)):\n",
    "        lat_sect += latin_soup[i].findAll(tag, {typename: typos})\n",
    "    for i in range(len(eng_soup)):\n",
    "        eng_sect += eng_soup[i].findAll(tag, {typename: typos})\n",
    "\n",
    "    if len(lat_sect) > len(eng_sect):\n",
    "        try:\n",
    "            #print(latin_soup[0]['n'],latin_soup[0].parent['n'])\n",
    "            m = match(lat_sect,eng_sect)\n",
    "            eng_alignments,lat_alignments = align_soups(m,eng_sect,lat_sect)\n",
    "            return lat_alignments,eng_alignments\n",
    "        except:\n",
    "            print(\"error with {}, {}\".format(tag,typos))\n",
    "    elif len(lat_sect) < len(eng_sect):\n",
    "        try:\n",
    "            #print(latin_soup[0]['n'],latin_soup[0].name)\n",
    "            m = match(eng_sect,lat_sect)\n",
    "            lat_alignments,eng_alignments = align_soups(m,lat_sect,eng_sect)\n",
    "            return lat_alignments,eng_alignments\n",
    "        except:\n",
    "            print(\"error with {}, {}\".format(tag,typos))\n",
    "    else:\n",
    "        if eng_sect[0]['n'] == 'intro':\n",
    "            try:\n",
    "                #print(latin_soup[0]['n'],latin_soup[0].name)\n",
    "                m = match(eng_sect,lat_sect)\n",
    "                lat_alignments,eng_alignments = align_soups(m,lat_sect,eng_sect)\n",
    "                return lat_alignments,eng_alignments\n",
    "            except:\n",
    "                print(\"error with {}, {}\".format(tag,typos))\n",
    "        else:\n",
    "            \n",
    "            return lat_sect, eng_sect\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def align_pars(lsentences,esentences):\n",
    "    \n",
    "    if lsentences[-1] == '':\n",
    "        lsentences = lsentences[:-1]\n",
    "    if esentences[-1] == '':\n",
    "        esentences = esentences[:-1]\n",
    "        \n",
    "    if len(lsentences) > len(esentences):\n",
    "        alignments = align(lsentences,esentences)\n",
    "        target = esentences\n",
    "        source = lsentences\n",
    "    elif len(lsentences) < len(esentences):\n",
    "        alignments = align(esentences,lsentences)\n",
    "        target = lsentences\n",
    "        source = esentences\n",
    "    else:\n",
    "        return zip(lsentences,esentences)\n",
    "    \n",
    "    sentence_tuples = []\n",
    "    for k in alignments.keys():\n",
    "        sentence_tuples.append((target[k], [source[j] for j in alignments[k]]))\n",
    "        \n",
    "    return sentence_tuples\n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "def clean_lemma(word):\n",
    "    try:\n",
    "        word = re.sub('[0-9]+', '', word)\n",
    "        word = re.sub('[-_]+', '', word)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return word\n",
    "\n",
    "\n",
    "def get_lemmata_defs(latin):\n",
    "    words = lemmatizer.lemmatize(latin)\n",
    "    ldefs = []\n",
    "    unmatched = []\n",
    "\n",
    "    for word in words:\n",
    "        word = clean_lemma(word)\n",
    "        try:\n",
    "            ldefs.append(defs[word]['definition'].split(','))\n",
    "        except:\n",
    "            unmatched.append(word)\n",
    "    return ldefs,unmatched\n",
    "\n",
    "\n",
    "def get_defs(ldefs):\n",
    "    lldefs=[]\n",
    "    for l in ldefs:\n",
    "        lldefs += t(l[0])\n",
    "    return lldefs\n",
    "\n",
    "\n",
    "def get_match_count(english,latin):\n",
    "    \n",
    "    ldefs,unmatched = get_lemmata_defs(latin)\n",
    "    ldefs = get_defs(ldefs)\n",
    "    count = 0\n",
    "    for word in t(english):\n",
    "        if word in string.punctuation:\n",
    "            continue\n",
    "        if word in ldefs and word not in stop:\n",
    "            count += 1\n",
    "        if word in unmatched:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def align(source,target):\n",
    "    \"\"\" Takes a paragraph of sentences, source, and maps each sentence to a sentence in the \n",
    "        target paragraph. \n",
    "        \n",
    "        Returns a dictionary with the target sentence indices as keys, and the sentences in the source paragraph\n",
    "        which correspond to them as values.\n",
    "    \"\"\"\n",
    "    tsize = len(target)\n",
    "    ssize = len(source)\n",
    "    alignments = defaultdict(list)\n",
    "    alignments[0] = [0]\n",
    "    i = 1\n",
    "    j = 1\n",
    "    while tsize < ssize and i < len(source) and j < tsize:\n",
    "        max_count = get_match_count(source[i],target[j])\n",
    "        max_i = j\n",
    "        if j >= tsize-1:\n",
    "            rge = [j-1]\n",
    "        else:\n",
    "            rge = [j-1,j+1]\n",
    "        for r in rge: \n",
    "            c = get_match_count(source[i],target[r])\n",
    "            if c > max_count:\n",
    "                max_count = c\n",
    "                max_i = r\n",
    "\n",
    "        if max_i != j:\n",
    "            ssize -= 1\n",
    "        else:\n",
    "            j += 1\n",
    "\n",
    "        alignments[max_i].append(i)\n",
    "        i += 1\n",
    "        \n",
    "  \n",
    "    while j < tsize:\n",
    "        alignments[j].append(i)\n",
    "        j += 1\n",
    "        i += 1\n",
    "    alignments[j-1].extend([k for k in range(i,len(source))])\n",
    "    \n",
    "    return alignments\n",
    "\n",
    "def get_sec_alignments(lpar,epar):\n",
    "    if len(lpar) > len(epar):\n",
    "        if len(epar) > 1:\n",
    "            alignments = align(lpar,epar)\n",
    "            aligned = []\n",
    "            for k in alignments.keys():\n",
    "                group = []\n",
    "                for v in alignments[k]:\n",
    "                    group.append(lpar[v])\n",
    "                aligned.append((group,epar[k]))\n",
    "        else:\n",
    "            try:\n",
    "                aligned = [('. '.join(lpar),epar[0])] \n",
    "            except:\n",
    "                print('error, {}'.format(epar))\n",
    "                aligned = list(zip(lpar,epar))\n",
    "    elif len(epar) > len(lpar):\n",
    "        if len(lpar) > 1:\n",
    "            alignments = align(epar,lpar)\n",
    "            aligned = []\n",
    "            for k in alignments.keys():\n",
    "                group = []\n",
    "                for v in alignments[k]:\n",
    "                    group.append(epar[v])\n",
    "                aligned.append((lpar[k],group))\n",
    "        else:\n",
    "            try:\n",
    "                aligned = [(lpar[0],'. '.join(epar))]\n",
    "            except:\n",
    "                print('error, {}'.format(lpar))\n",
    "                aligned = list(zip(lpar,epar))\n",
    "    else:\n",
    "        aligned = list(zip(lpar,epar))\n",
    "        \n",
    "    return aligned\n",
    "\n",
    "def get_sentences(chap_soup, sect_soup):\n",
    "    t = bs4.element.Tag\n",
    "    sect = []\n",
    "    sentences = []\n",
    "    i = 0\n",
    "    c = 0\n",
    "    children = list(chap_soup.children)\n",
    "    soup = children[c].find('milestone')#, {'n':sect_soup[i]['n']})\n",
    "    c += 1\n",
    "    while type(soup) != t:\n",
    "        soup = children[c].find('milestone')#, {'n':sect_soup[i]['n']})\n",
    "        c += 1\n",
    "    i += 1\n",
    "    while c < len(children):\n",
    "        print(sentences)\n",
    "        while soup.next_sibling != None:\n",
    "            soup = soup.next_sibling\n",
    "            if soup.name == 'milestone':\n",
    "                try:\n",
    "                    if int(soup['n']) == int(sect_soup[i]['n']):\n",
    "                        i += 1\n",
    "                        sentences.append(' '.join(sect))\n",
    "                        sect = []\n",
    "                except:\n",
    "                    soup = soup.next_sibling\n",
    "                    i += 1\n",
    "            if soup.name in ['corr', 'name','hi','quote','reg', 'l', 'lg', 'placeName']:\n",
    "                    sect.append(soup.text.strip())\n",
    "            elif soup.name == None:\n",
    "                    sect.append(soup.strip())\n",
    "                    \n",
    "        sentences.append(' '.join(sect))\n",
    "        sect = []\n",
    "        try:\n",
    "            soup = children[c].find('milestone')#, {'n':sect_soup[i]['n']})\n",
    "            c += 1\n",
    "            while type(soup) != t and c < len(children):\n",
    "                soup = children[c].find('milestone')\n",
    "                c += 1\n",
    "            i += 1\n",
    "        except:\n",
    "            continue\n",
    "    sentences.append(' '.join(sect))\n",
    "    sect = []\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = wordpunct_tokenize\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "f = open('../lemmas.json')\n",
    "defs = json.loads(f.read())\n",
    "\n",
    "lemmatizer = LemmaReplacer('latin')\n",
    "tokenizer = WordTokenizer('latin')\n",
    "s_tokenizer = TokenizeSentence('latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('../../Latin/Vitruvius/opensource/vitruv_lat.xml')\n",
    "ltext = f.read()\n",
    "f.close()\n",
    "f = open('../../Latin/Vitruvius/opensource/vitruv_eng.xml')\n",
    "etext = f.read()\n",
    "f.close()\n",
    "\n",
    "lat_sections = re.split(r'<div1 type=\"book\" n=\"\\d*\">', ltext)[1:]\n",
    "eng_sections = re.split(r'<div1 type=\"book\" n=\"\\d*\">', etext)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lat_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eng_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sects = list(zip(lat_sections,eng_sections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lchaps = []\n",
    "echaps = []\n",
    "\n",
    "for sect in sects:\n",
    "    lchaps.append(re.split(r'<div2 type=\"chapter\" n=\".+\">', sect[0])[1:])\n",
    "    echaps.append(re.split(r'<div2 type=\"chapter\" n=\".+\">', sect[1])[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<div3 type=\"section\" n=\"1\"><p>Architectura autem constat ex ordinatione, quae graece\\n<foreign lang=\"greek\">ta/cis</foreign> dicitur, et ex dispositione, hanc autem Graeci <foreign lang=\"greek\">dia/qesin</foreign> vocitant, et eurythmia et symmetria et decore et\\ndistributione, quae graece <foreign lang=\"greek\">oi)konomi/a</foreign> dicitur.\\n</p></div3>\\n<div3 type=\"section\" n=\"2\"><p>Ordinatio est [modica] membrorum operis [commoditas]\\nseparatim universeque proportionis ad symmetriam comparatio. haec componitur ex quantitate, quae graece\\n<foreign lang=\"greek\">poso/ths</foreign> dicitur. quantitas autem est modulorum ex ipsius\\noperis e singulisque membrorum partibus sumptio universi operis conveniens effectui.</p>\\n<p>Dispositio autem est rerum apta conlocatio elegansque\\ncompositionibus effectus operis cum qualitate. species dispositionis, quae graece dicuntur <foreign lang=\"greek\">i)de/ai</foreign>, sunt hae: ichnographia, orthographia, scaenographia. ichnographia est\\ncircini regulaeque modice continens usus, e qua capiuntur formarum in solis arearum descriptiones. orthographia autem est erecta frontis imago modiceque picta\\nrationibus operis futuri figura. item scaenographia est\\nfrontis et laterum abscedentium adumbratio ad circinique \\ncentrum omnium linearum responsus. hae nascuntur\\nex cogitatione et inventione. cogitatio est cura studii\\nplena et industriae vigilantiaeque effectus propositi cum\\nvoluptate. inventio autem est quaestionum obscurarum\\nexplicatio ratioque novae rei vigore mobili reperta. hae\\nsunt terminationes dispositionum.\\n</p></div3>\\n<div3 type=\"section\" n=\"3\"><p>Eurythmia est venusta species commodusque in compositionibus membrorum aspectus. haec efficitur, cum membra operis convenientis sunt altitudinis ad latitudinem, latitudinis ad longitudinem, et ad summam omnia respondent\\nsuae symmetriae.\\n</p></div3>\\n<div3 type=\"section\" n=\"4\"><p>Item symmetria est ex ipsius operis membris conveniens\\nconsensus ex partibusque separatis ad universae figurae\\nspeciem ratae partis responsus. uti in hominis corpore e\\ncubito, pede, palmo, digito ceterisque particulis symmetros\\nest eurythmiae qualitas, sic est in operum perfectionibus.\\net primum in aedibus sacris aut e columnarum crassitudinibus aut triglypho aut etiam embatere, ballista e foramine &lt;capituli&gt;, quod Graeci <foreign lang=\"greek\">peri/trhton</foreign> vocitant, navibus\\ninterscalmio, quae <foreign lang=\"greek\">dia/phgma</foreign> dicitur, item ceterorum operum\\ne membris invenitur symmetriarum ratiocinatio.\\n</p></div3>\\n<div3 type=\"section\" n=\"5\"><p>Decor autem est emendatus operis aspectus probatis\\nrebus compositi cum auctoritate. is perficitur statione,\\nquod graece <foreign lang=\"greek\">qematismw=|</foreign> dicitur, seu consuetudine aut\\nnatura. statione, cum Iovi Fulguri et Caelo et Soli et\\nLunae aedificia sub divo hypaethraque constituentur; horum enim deorum et species et effectus in aperto mundo\\natque lucenti praesentes videmus. Minervae et Marti et\\nHerculi aedes doricae fient; his enim diis propter virtutem\\nsine deliciis aedificia constitui decet. Veneri, Florae, Proserpinae, fontium nymphis corinthio genere constitutae\\naptas videbuntur habere proprietates, quod his diis propter\\nteneritatem graciliora et florida foliisque et volutis ornata\\nopera facta augere videbuntur iustum decorem. Iunoni,\\nDianae, Libero Patri ceterisque diis, qui eadem sunt similitudine, si aedes ionicae construentur, habita erit ratio\\nmediocritatis, quod et ab severo more doricorum et ab\\nteneritate corinthiorum temperabitur earum institutio proprietatis.\\n</p></div3>\\n<div3 type=\"section\" n=\"6\"><p>Ad consuetudinem autem decor sic exprimitur,\\ncum aedificiis interioribus magnificis item vestibula convenientia et elegantia erunt facta. si enim interiora prospectus habuerint elegantes, aditus autem humiles et inhonestos, non erunt cum decore. item si doricis epistyliis in\\ncoronis denticuli sculpentur aut in pulvinatis columnis ex\\nionicis epistyliis [capitulis] exprimentur triglyphi, translatis\\nex alia ratione proprietatibus in aliud genus operis offendetur aspectus aliis ante ordinis consuetudinibus institutus.\\n</p></div3>\\n<div3 type=\"section\" n=\"7\"><p>Naturalis autem decor sic erit, si primum omnibus templis\\nsaluberrimae regiones aquarumque fontes in &icirc;s locis idonei\\neligentur, in quibus fana constituantur, deinde maxime\\nAesculapio, Saluti, ut eorum deorum, quorum plurimi medicinis aegri curari videntur. cum enim ex pestilenti in\\nsalubrem locum corpora aegra translata fuerint et e fontibus salubribus aquarum usus subministrabuntur, celerius\\nconvalescent. ita efficietur, uti ex natura loci maiores\\nauctasque cum dignitate divinitas excipiat opiniones. item\\nnaturae decor erit, si cubiculis et bybliothecis ab oriente\\nlumina capiuntur, balneis et hibernaculis ab occidente hiberno, pinacothecis et quibus certis luminibus opus est\\npartibus, a septentrione, quod ea caeli regio neque exclaratur neque obscuratur solis cursu sed est certa inmutabilis die perpetuo.\\n</p></div3>\\n<div3 type=\"section\" n=\"8\"><p>Distributio autem est copiarum locique commoda dispensatio parcaque in operibus sumptus ratione temperatio.\\nhaec ita observabitur, si primum architectus ea non quaeret, quae non poterunt inveniri aut parari nisi magno.\\nnamque non omnibus locis harenae fossiciae nec caementorum nec abietis nec sappinorum nec marmoris copia est,\\nsed aliud alio loco nascitur, quorum comportationes difficiles sunt et sumptuosae. utendum autem est, ubi non est\\nharena fossicia, fluviatica aut marina lota; inopiae quoque\\nabietis aut sappinorum vitabuntur utendo cupresso, populo, ulmo, pinu; reliquaque his similiter erunt explicanda.\\n</p></div3>\\n<div3 type=\"section\" n=\"9\"><p>Alter gradus erit distributionis, cum ad usum patrum familiarum\\net ad pecuniae copiam aut ad eloquentiae dignitatem aedificia apte disponentur. namque aliter urbanas domos oportere constitui videtur, aliter quibus ex possessionibus rusticis influunt fructus; non item feneratoribus, aliter beatis\\net delicatis; potentibus vero, quorum cogitationibus respublica gubernatur, ad usum conlocabuntur; et omnino\\nfaciendae sunt aptae omnibus personis aedificiorum distributiones.\\n</p></div3>\\n</div2>\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lchaps[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8\n",
      "11 11\n",
      "6 6\n",
      "10 10\n",
      "13 13\n",
      "9 9\n",
      "15 15\n",
      "7 7\n",
      "9 9\n",
      "17 17\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lchaps)):\n",
    "    print(len(lchaps[i]),len(echaps[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sects = list(zip(lchaps,echaps)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsects = []\n",
    "esects = []\n",
    "\n",
    "for b in range(len(lchaps)):\n",
    "    for c in range(len(lchaps[b])):\n",
    "        lsp = re.split(r'<div3 type=\"section\" n=\"\\d+\">', lchaps[b][c])\n",
    "        esp = re.split(r'<div3 type=\"section\" n=\"\\d+\">', echaps[b][c])\n",
    "        while '\\n' in lsp:\n",
    "            lsp.remove('\\n')\n",
    "        while '\\n' in esp:\n",
    "            esp.remove('\\n')\n",
    "        if '<head>' in esp[0]:\n",
    "            esp = esp[1:]\n",
    "        if '<head>' in lsp[0]:\n",
    "            lsp = lsp[1:]\n",
    "        lsects.append(lsp)\n",
    "        esects.append(esp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<p>Cum divina tua mens et numen, imperator Caesar, imperio potiretur orbis terrarum invictaque virtute cunctis\\nhostibus stratis triumpho victoriaque tua cives gloriarentur\\net gentes omnes subactae tuum spectarent nutum populusque Romanus et senatus liberatus timore amplissimis tuis\\ncogitationibus consiliisque gubernaretur, non audebam,\\ntantis occupationibus, de architectura scripta et magnis\\ncogitationibus explicata edere, metuens, ne non apto tempore interpellans subirem tui animi offensionem.\\n</p></div3>\\n',\n",
       " '<p>Cum vero attenderem te non solum de vita communi omnium curam\\npublicaeque rei constitutione habere sed etiam de opportunitate publicorum aedificiorum, ut civitas per te non\\nsolum provinciis esset aucta, verum etiam ut maiestas\\nimperii publicorum aedificiorum egregias haberet auctoritates, non putavi praetermittendum, quin primo quoque\\ntempore de his rebus ea tibi ederem, ideo quod primum\\nparenti tuo [de eo] fueram notus et eius virtutis studiosus.\\ncum autem concilium caelestium in sedibus inmortalitatis\\neum dedicavisset et imperium parentis in tuam potestatem\\ntranstulisset, idem studium meum in eius memoria permanens in te contulit favorem. \\n</p>\\n<p>Itaque cum M. Aurelio et P. Minidio et Gn. Cornelio ad apparationem ballistarum\\net scorpionum reliquorumque tormentorum refectionem\\nfui praesto et cum eis commoda accepi, quae, cum primo\\nmihi tribuisti recognitionem, per sororis commendationem servasti.\\n</p>\\n</div3>\\n',\n",
       " '<p>Cum ergo eo beneficio essem obligatus, ut ad\\nexitum vitae non haberem inopiae timorem, haec tibi\\nscribere coepi, quod animadverti multa te aedificavisse\\net nunc aedificare, reliquo quoque tempore et publicorum et\\nprivatorum aedificiorum, pro amplitudine rerum gestarum\\nut posteris memoriae traderentur, curam habiturum. conscripsi praescriptiones terminatas, ut eas attendens et ante\\nfacta et futura qualia sint opera per te posses nota habere;\\nnamque his voluminibus aperui omnes disciplinae rationes.\\n</p></div3>\\n</div2>\\n']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsects[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3\n",
      "18 17\n",
      "9 9\n",
      "2 2\n",
      "12 12\n",
      "8 8\n",
      "13 13\n",
      "2 2\n",
      "6 5\n",
      "9 9\n",
      "2 2\n",
      "4 4\n",
      "3 3\n",
      "3 3\n",
      "6 6\n",
      "5 5\n",
      "20 20\n",
      "17 17\n",
      "3 3\n",
      "4 4\n",
      "9 9\n",
      "8 8\n",
      "13 13\n",
      "5 5\n",
      "15 15\n",
      "2 1\n",
      "12 12\n",
      "6 6\n",
      "10 9\n",
      "4 4\n",
      "2 1\n",
      "6 6\n",
      "5 5\n",
      "7 7\n",
      "1 1\n",
      "5 5\n",
      "9 10\n",
      "2 2\n",
      "8 8\n",
      "9 9\n",
      "8 8\n",
      "9 9\n",
      "2 2\n",
      "2 2\n",
      "9 9\n",
      "5 5\n",
      "4 4\n",
      "7 7\n",
      "7 7\n",
      "12 12\n",
      "5 5\n",
      "11 11\n",
      "2 2\n",
      "3 3\n",
      "7 7\n",
      "7 7\n",
      "10 10\n",
      "18 18\n",
      "7 7\n",
      "2 2\n",
      "11 11\n",
      "5 5\n",
      "8 8\n",
      "1 1\n",
      "5 5\n",
      "4 4\n",
      "6 6\n",
      "4 4\n",
      "2 2\n",
      "2 2\n",
      "3 3\n",
      "3 3\n",
      "4 4\n",
      "7 7\n",
      "9 9\n",
      "28 28\n",
      "2 2\n",
      "3 3\n",
      "15 14\n",
      "18 18\n",
      "16 16\n",
      "4 4\n",
      "3 3\n",
      "6 6\n",
      "4 4\n",
      "3 3\n",
      "7 7\n",
      "15 15\n",
      "4 4\n",
      "6 6\n",
      "15 15\n",
      "9 9\n",
      "4 4\n",
      "2 2\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "6 6\n",
      "9 9\n",
      "2 2\n",
      "8 8\n",
      "3 3\n",
      "7 7\n",
      "12 12\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lsects)):\n",
    "    print(len(lsects[i]),len(esects[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_sects = esects\n",
    "lat_sects = lsects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lat_text = []\n",
    "eng_text = []\n",
    "\n",
    "for s in range(len(eng_sects)):\n",
    "    if len(eng_sects[s]) != len(lat_sects[s]):\n",
    "        continue\n",
    "        \n",
    "    for c in range(len(eng_sects[s])):\n",
    "        es = eng_sects[s][c]\n",
    "        if re.match(r'</.>',es):\n",
    "            es = re.split(r'</.>',es,maxsplit=1)[1]\n",
    "        soup = BeautifulSoup(es,'lxml')\n",
    "        if soup.find('note'):\n",
    "            es = re.sub(r'<note[^>.]*>', '<note>', es,flags=re.DOTALL)\n",
    "            sp = re.split(r'<note>',es)\n",
    "            es = sp[0]\n",
    "            for n in sp[1:]:\n",
    "                n = re.sub(r'.*</note>', \" \", n,flags=re.DOTALL)\n",
    "                es += n\n",
    "            soup = BeautifulSoup(es,'lxml')\n",
    "            eng_text.append(soup.text)\n",
    "        else:\n",
    "            eng_text.append(soup.text)\n",
    "\n",
    "        ls = lat_sects[s][c]\n",
    "        if re.match(r'</.>',ls):\n",
    "            el = re.split(r'</.>',ls,maxsplit=1)[1]\n",
    "        soup = BeautifulSoup(ls,'lxml')\n",
    "        if soup.find('note'):\n",
    "            ls = re.sub(r'<note[^>.]*>', '<note>', ls,flags=re.DOTALL)\n",
    "            sp = re.split(r'<note>',ls)\n",
    "            ls = sp[0]\n",
    "            for n in sp[1:]:\n",
    "                n = re.sub(r'.*</note>', \" \", n,flags=re.DOTALL)\n",
    "                ls += n\n",
    "            soup = BeautifulSoup(ls,'lxml')\n",
    "            lat_text.append(soup.text)\n",
    "        else:\n",
    "            lat_text.append(soup.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, []\n",
      "error, []\n"
     ]
    }
   ],
   "source": [
    "alignments = []\n",
    "\n",
    "for c in range(len(eng_text)):\n",
    "    es = ' '.join(eng_text[c].replace('\\n',' ').split())\n",
    "    ls = lat_text[c].replace('\\n', ' ')\n",
    "\n",
    "    ls = re.sub(r'\\. \\. \\.','',ls)\n",
    "    es = re.sub(r'\\. \\. \\.','',es)\n",
    "    ls = re.sub('[:;,]','',ls)\n",
    "    es = re.sub('[:;,]','',es)\n",
    "    es = re.sub('\\d+\\.','',es)\n",
    "\n",
    "    epar = sent_tokenize(es)\n",
    "    lpar = s_tokenizer.tokenize_sentences(ls)\n",
    "    alignments.append(get_sec_alignments(lpar,epar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Cum vero attenderem te non solum de vita communi omnium curam publicaeque rei constitutione habere sed etiam de opportunitate publicorum aedificiorum ut civitas per te non solum provinciis esset aucta verum etiam ut maiestas imperii publicorum aedificiorum egregias haberet auctoritates non putavi praetermittendum quin primo quoque tempore de his rebus ea tibi ederem ideo quod primum parenti tuo [de eo] fueram notus et eius virtutis studiosus.',\n",
       "  [' But when I saw that you were giving your attention not only to the welfare of society in general and to the establishment of public order but also to the providing of public buildings intended for utilitarian purposes so that not only should the State have been enriched with provinces by your means but that the greatness of its power might likewise be attended with distinguished authority in its public buildings I thought that I ought to take the first opportunity to lay before you my writings on this theme.']),\n",
       " ('cum autem concilium caelestium in sedibus inmortalitatis eum dedicavisset et imperium parentis in tuam potestatem transtulisset idem studium meum in eius memoria permanens in te contulit favorem.',\n",
       "  ['For in the first place it was this subject which made me known to your father to whom I was devoted on account of his great qualities.',\n",
       "   \"After the council of heaven gave him a place in the dwellings of immortal life and transferred your father's power to your hands my devotion continuing unchanged as I remembered him inclined me to support you.\"]),\n",
       " ('Itaque cum M. Aurelio et P. Minidio et Gn.',\n",
       "  ['And so with Marcus Aurelius Publius Minidius and Gnaeus Cornelius I was ready to supply and repair ballistae scorpiones and other artillery and I have received rewards for good service with them.']),\n",
       " ('Cornelio ad apparationem ballistarum et scorpionum reliquorumque tormentorum refectionem fui praesto et cum eis commoda accepi quae cum primo mihi tribuisti recognitionem per sororis commendationem servasti.  ',\n",
       "  ['After your first bestowal of these upon me you continued to renew them on the recommendation of your sister.'])]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignments[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for a in alignments:\n",
    "        count += len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2208"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('../aligned_sentences/vitruvius_sentences.json','w') \n",
    "j = json.dumps(alignments)\n",
    "f.write(j)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
