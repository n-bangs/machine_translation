{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from cltk.stem.lemma import LemmaReplacer\n",
    "from cltk.tokenize.word import WordTokenizer\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from cltk.tokenize.sentence import TokenizeSentence\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import bs4\n",
    "\n",
    "def make_list(soup):\n",
    "    l = []\n",
    "    for n in soup:\n",
    "        try:\n",
    "            l.append(int(n['n']))\n",
    "        except:\n",
    "            l.append(-1)  \n",
    "    return remove_duplicates(l)\n",
    "\n",
    "\n",
    "def remove_duplicates(l):\n",
    "    i = 0\n",
    "    while i+1 < len(l):\n",
    "        if l[i] == l[i+1]:\n",
    "            l[i+1] += 1\n",
    "        if l[i] > l[i+1] and l[i+1] != -1:\n",
    "            l[i] = l[i+1]-1\n",
    "        i += 1\n",
    "    return l\n",
    "\n",
    "def match(large,small):\n",
    "    l = make_list(large)\n",
    "    s = make_list(small)\n",
    "    li = 0\n",
    "    si = 0\n",
    "    groups = []\n",
    "    #print(l,s)\n",
    "    while si < len(s) and li < len(l):\n",
    "        if s[si] == -1:\n",
    "            si += 1\n",
    "            continue\n",
    "        if l[li] == -1:\n",
    "            li += 1\n",
    "            continue\n",
    "        lgroup = []\n",
    "        sgroup = []\n",
    "        if l[li] == s[si]:\n",
    "            lgroup.append(li)\n",
    "            sgroup.append(si)\n",
    "              \n",
    "        if si+1 < len(s) and li+1 < len(l): \n",
    "            if s[si+1] == -1:\n",
    "                si += 1\n",
    "            \n",
    "            if l[li+1] == -1:\n",
    "                li += 1\n",
    "            \n",
    "            \n",
    "            if l[li+1] != s[si+1]:\n",
    "                while l[li+1] != s[si+1]:\n",
    "                    if si+1 < len(s) and li+1 < len(l):\n",
    "                        if l[li+1] > s[si+1]:\n",
    "                            sgroup.append(si+1)\n",
    "                            si += 1\n",
    "                            if s[si] == -1:\n",
    "                                if si+1 < len(s):\n",
    "                                    si += 1\n",
    "                                else:\n",
    "                                    pass\n",
    "                        else:\n",
    "                            lgroup.append(li+1)\n",
    "                            li += 1\n",
    "                            if l[li] == -1:\n",
    "                                if li+1 < len(l):\n",
    "                                    li += 1\n",
    "                                else:\n",
    "                                    pass\n",
    "                    else:\n",
    "                        break\n",
    "                si += 1\n",
    "                li += 1\n",
    "                groups.append([sgroup,lgroup])\n",
    "            else:\n",
    "                si += 1\n",
    "                li += 1\n",
    "                groups.append([sgroup,lgroup]) \n",
    "        else:\n",
    "            break        \n",
    "    \n",
    "    groups.append([sgroup,lgroup])\n",
    "    return groups\n",
    "        \n",
    "\n",
    "def align_soups(m,small,large):\n",
    "    s_alignments = []\n",
    "    l_alignments = []\n",
    "    for g in m:\n",
    "        s = []\n",
    "        l = []\n",
    "        for i in g[0]:\n",
    "            s.append(small[i])\n",
    "        for i in g[1]:\n",
    "            l.append(large[i])\n",
    "        s_alignments.append(s)\n",
    "        l_alignments.append(l)   \n",
    "    return s_alignments,l_alignments\n",
    "\n",
    "\n",
    "def get_pairs(latin_soup, eng_soup, tag, typename, typos):\n",
    "    \"\"\" Given two soups, returns soups of equal size, with each element corresponding to the same\n",
    "        element in the other soup.\n",
    "        Lists may contain further lists of soups which are aligned with one another, they are combined into one list\n",
    "        in the first step of this function.\n",
    "    \"\"\"\n",
    "    lat_sect,eng_sect = [], []\n",
    "    \n",
    "    for i in range(len(latin_soup)):\n",
    "        lat_sect += latin_soup[i].findAll(tag, {typename: typos})\n",
    "    for i in range(len(eng_soup)):\n",
    "        eng_sect += eng_soup[i].findAll(tag, {typename: typos})\n",
    "\n",
    "    if len(lat_sect) > len(eng_sect):\n",
    "        try:\n",
    "            #print(latin_soup[0]['n'],latin_soup[0].parent['n'])\n",
    "            m = match(lat_sect,eng_sect)\n",
    "            eng_alignments,lat_alignments = align_soups(m,eng_sect,lat_sect)\n",
    "            return lat_alignments,eng_alignments\n",
    "        except:\n",
    "            print(\"error with {}, {}\".format(tag,typos))\n",
    "    elif len(lat_sect) < len(eng_sect):\n",
    "        try:\n",
    "            #print(latin_soup[0]['n'],latin_soup[0].name)\n",
    "            m = match(eng_sect,lat_sect)\n",
    "            lat_alignments,eng_alignments = align_soups(m,lat_sect,eng_sect)\n",
    "            return lat_alignments,eng_alignments\n",
    "        except:\n",
    "            print(\"error with {}, {}\".format(tag,typos))\n",
    "    else:\n",
    "        if eng_sect[0]['n'] == 'intro':\n",
    "            try:\n",
    "                #print(latin_soup[0]['n'],latin_soup[0].name)\n",
    "                m = match(eng_sect,lat_sect)\n",
    "                lat_alignments,eng_alignments = align_soups(m,lat_sect,eng_sect)\n",
    "                return lat_alignments,eng_alignments\n",
    "            except:\n",
    "                print(\"error with {}, {}\".format(tag,typos))\n",
    "        else:\n",
    "            \n",
    "            return lat_sect, eng_sect\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def align_pars(lsentences,esentences):\n",
    "    \n",
    "    if lsentences[-1] == '':\n",
    "        lsentences = lsentences[:-1]\n",
    "    if esentences[-1] == '':\n",
    "        esentences = esentences[:-1]\n",
    "        \n",
    "    if len(lsentences) > len(esentences):\n",
    "        alignments = align(lsentences,esentences)\n",
    "        target = esentences\n",
    "        source = lsentences\n",
    "    elif len(lsentences) < len(esentences):\n",
    "        alignments = align(esentences,lsentences)\n",
    "        target = lsentences\n",
    "        source = esentences\n",
    "    else:\n",
    "        return zip(lsentences,esentences)\n",
    "    \n",
    "    sentence_tuples = []\n",
    "    for k in alignments.keys():\n",
    "        sentence_tuples.append((target[k], [source[j] for j in alignments[k]]))\n",
    "        \n",
    "    return sentence_tuples\n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "def clean_lemma(word):\n",
    "    try:\n",
    "        word = re.sub('[0-9]+', '', word)\n",
    "        word = re.sub('[-_]+', '', word)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return word\n",
    "\n",
    "\n",
    "def get_lemmata_defs(latin):\n",
    "    words = lemmatizer.lemmatize(latin)\n",
    "    ldefs = []\n",
    "    unmatched = []\n",
    "\n",
    "    for word in words:\n",
    "        word = clean_lemma(word)\n",
    "        try:\n",
    "            ldefs.append(defs[word]['definition'].split(','))\n",
    "        except:\n",
    "            unmatched.append(word)\n",
    "    return ldefs,unmatched\n",
    "\n",
    "\n",
    "def get_defs(ldefs):\n",
    "    lldefs=[]\n",
    "    for l in ldefs:\n",
    "        lldefs += t(l[0])\n",
    "    return lldefs\n",
    "\n",
    "\n",
    "def get_match_count(english,latin):\n",
    "    \n",
    "    ldefs,unmatched = get_lemmata_defs(latin)\n",
    "    ldefs = get_defs(ldefs)\n",
    "    count = 0\n",
    "    for word in t(english):\n",
    "        if word in string.punctuation:\n",
    "            continue\n",
    "        if word in ldefs and word not in stop:\n",
    "            count += 1\n",
    "        if word in unmatched:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def align(source,target):\n",
    "    \"\"\" Takes a paragraph of sentences, source, and maps each sentence to a sentence in the \n",
    "        target paragraph. \n",
    "        \n",
    "        Returns a dictionary with the target sentence indices as keys, and the sentences in the source paragraph\n",
    "        which correspond to them as values.\n",
    "    \"\"\"\n",
    "    tsize = len(target)\n",
    "    ssize = len(source)\n",
    "    alignments = defaultdict(list)\n",
    "    alignments[0] = [0]\n",
    "    i = 1\n",
    "    j = 1\n",
    "    while tsize < ssize and i < len(source) and j < tsize:\n",
    "        max_count = get_match_count(source[i],target[j])\n",
    "        max_i = j\n",
    "        if j >= tsize-1:\n",
    "            rge = [j-1]\n",
    "        else:\n",
    "            rge = [j-1,j+1]\n",
    "        for r in rge: \n",
    "            c = get_match_count(source[i],target[r])\n",
    "            if c > max_count:\n",
    "                max_count = c\n",
    "                max_i = r\n",
    "\n",
    "        if max_i != j:\n",
    "            ssize -= 1\n",
    "        else:\n",
    "            j += 1\n",
    "\n",
    "        alignments[max_i].append(i)\n",
    "        i += 1\n",
    "        \n",
    "  \n",
    "    while j < tsize:\n",
    "        alignments[j].append(i)\n",
    "        j += 1\n",
    "        i += 1\n",
    "    alignments[j-1].extend([k for k in range(i,len(source))])\n",
    "    \n",
    "    return alignments\n",
    "\n",
    "def get_sec_alignments(lpar,epar):\n",
    "    if len(lpar) > len(epar):\n",
    "        if len(epar) > 1:\n",
    "            alignments = align(lpar,epar)\n",
    "            aligned = []\n",
    "            for k in alignments.keys():\n",
    "                group = []\n",
    "                for v in alignments[k]:\n",
    "                    group.append(lpar[v])\n",
    "                aligned.append((group,epar[k]))\n",
    "        else:\n",
    "            try:\n",
    "                aligned = [('. '.join(lpar),epar[0])] \n",
    "            except:\n",
    "                print('error, {}'.format(epar))\n",
    "                aligned = list(zip(lpar,epar))\n",
    "    elif len(epar) > len(lpar):\n",
    "        if len(lpar) > 1:\n",
    "            alignments = align(epar,lpar)\n",
    "            aligned = []\n",
    "            for k in alignments.keys():\n",
    "                group = []\n",
    "                for v in alignments[k]:\n",
    "                    group.append(epar[v])\n",
    "                aligned.append((lpar[k],group))\n",
    "        else:\n",
    "            try:\n",
    "                aligned = [(lpar[0],'. '.join(epar))]\n",
    "            except:\n",
    "                print('error, {}'.format(lpar))\n",
    "                aligned = list(zip(lpar,epar))\n",
    "    else:\n",
    "        aligned = list(zip(lpar,epar))\n",
    "        \n",
    "    return aligned\n",
    "\n",
    "def get_sentences(chap_soup, sect_soup):\n",
    "    t = bs4.element.Tag\n",
    "    sect = []\n",
    "    sentences = []\n",
    "    i = 0\n",
    "    c = 0\n",
    "    children = list(chap_soup.children)\n",
    "    soup = children[c].find('milestone')#, {'n':sect_soup[i]['n']})\n",
    "    c += 1\n",
    "    while type(soup) != t:\n",
    "        soup = children[c].find('milestone')#, {'n':sect_soup[i]['n']})\n",
    "        c += 1\n",
    "    i += 1\n",
    "    while c < len(children):\n",
    "        print(sentences)\n",
    "        while soup.next_sibling != None:\n",
    "            soup = soup.next_sibling\n",
    "            if soup.name == 'milestone':\n",
    "                try:\n",
    "                    if int(soup['n']) == int(sect_soup[i]['n']):\n",
    "                        i += 1\n",
    "                        sentences.append(' '.join(sect))\n",
    "                        sect = []\n",
    "                except:\n",
    "                    soup = soup.next_sibling\n",
    "                    i += 1\n",
    "            if soup.name in ['corr', 'name','hi','quote','reg', 'l', 'lg', 'placeName']:\n",
    "                    sect.append(soup.text.strip())\n",
    "            elif soup.name == None:\n",
    "                    sect.append(soup.strip())\n",
    "                    \n",
    "        sentences.append(' '.join(sect))\n",
    "        sect = []\n",
    "        try:\n",
    "            soup = children[c].find('milestone')#, {'n':sect_soup[i]['n']})\n",
    "            c += 1\n",
    "            while type(soup) != t and c < len(children):\n",
    "                soup = children[c].find('milestone')\n",
    "                c += 1\n",
    "            i += 1\n",
    "        except:\n",
    "            continue\n",
    "    sentences.append(' '.join(sect))\n",
    "    sect = []\n",
    "    return sentences\n",
    "\n",
    "t = wordpunct_tokenize\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "f = open('../lemmas.json')\n",
    "defs = json.loads(f.read())\n",
    "\n",
    "lemmatizer = LemmaReplacer('latin')\n",
    "tokenizer = WordTokenizer('latin')\n",
    "s_tokenizer = TokenizeSentence('latin')\n",
    "\n",
    "f = open('../../Latin/Pliny/opensource/PlinyNH.xml')\n",
    "ltext = f.read()\n",
    "f.close()\n",
    "f = open('../../Latin/Pliny/opensource/pliny.maj.nh_eng.xml')\n",
    "etext = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat_books = re.split(r'<div0 type=\"book\" n=\"\\d\\d?\\d?\">', ltext)\n",
    "\n",
    "eng_books = re.split(r'<div1 type=\"book\" n=\"\\d\\d?\\d?\">', etext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat_books = lat_books[1:]\n",
    "eng_books = eng_books[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat_sects = []\n",
    "eng_sects = []\n",
    "\n",
    "for b in range(len(lat_books)):\n",
    "    lat_sects.append(re.split(r'<div1 type=\"chapter\" n=\"\\d\\d?\\d?\">', lat_books[b]))\n",
    "    eng_sects.append(re.split(r'<div2 type=\"chapter\" n=\"\\d\\d?\\d?\">', eng_books[b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re.split(r'<p>', lat_sects[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re.split(r'<p>', eng_sects[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lat_sects[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<head>CHAP. 1. (1.)&mdash;WHETHER THE WORLD BE FINITE, AND\\nWHETHER THERE BE MORE THAN ONE WORLD.</head>\\n\\n<p>The world<note anchored=\"yes\" place=\"foot\">\"Mundus.\" In translating from one language into another, it is\\nproper, as a general principle, always to render the same word in the\\noriginal by the same word in the translation. But to this rule there are\\ntwo exceptions; where the languages do not possess words which precisely correspond, and where the original author does not always use the\\nsame word in the same sense. Both these circumstances, I apprehend,\\napply to the case in question. The term <hi rend=\"ital\">Mundus</hi> is used by <placeName key=\"tgn,2588096\">Pliny</placeName>,\\nsometimes to mean <hi rend=\"ital\">the earth</hi> and its immediate appendages, the visible\\nsolar system; and at other times <hi rend=\"ital\">the universe;</hi> while I think we may\\nventure to assert, that in some instances it is used in rather a vague\\nmanner, without any distinct reference to either one or other of the above\\ndesignations. I have, in almost all cases, translated it by the term <hi rend=\"ital\">world,</hi>\\nas approaching nearest to the sense of the original. The word <hi rend=\"ital\">mundus</hi>\\nis frequently employed by Lucretius, especially in his fifth book, and\\nseems to be almost always used in the more extended sense of <hi rend=\"ital\">universe.</hi>\\nThere are, indeed, a few passages where either meaning would be equally\\nappropriate, and in one line it would appear to be equivalent to\\n<hi rend=\"ital\">firmament</hi> or <hi rend=\"ital\">heavens;</hi> \"et mundi speciem violare\\nserenam,\" iv. 138. <placeName key=\"tgn,2068515\">Cicero</placeName>,\\nin his treatise De Natura Deorum, generally uses the term <hi rend=\"ital\">mundus</hi> in the\\nsense of <hi rend=\"ital\">universe,</hi> as in ii. 22, 37, 58 and 154; while in one passage, ii.\\n132, it would appear to be employed in the more limited sense of <hi rend=\"ital\">the</hi>\\n<hi rend=\"ital\">earth.</hi> It occasionally occurs in the Fasti of <placeName key=\"tgn,2071526\">Ovid</placeName>, but it is not easy to\\nascertain its precise import; as in the line \"Post chaos, ut primum data\\nsunt tria corpora mundo,\" v. 41, where from the connexion it may be\\ntaken either in the more confined or in the more general sense. Manilius\\nemploys the word very frequently, and his commentators remark, that he\\nuses it in two distinct senses, <hi rend=\"ital\">the visible firmament</hi> and the <hi rend=\"ital\">universe;</hi> and\\nI am induced to think that he attaches still more meaning to the term.\\nIt occurs three times in the first eleven lines of his poem. In the third\\nline, \"deducere mundo aggredior,\" <hi rend=\"ital\">mundus</hi> may be considered as\\nequivalent to the celestial regions as opposed to the earth. In the\\nninth\\nline,\\n\"concessumque patri mundo,\" we may consider it as signifying the\\ncelestial regions generally; and in the eleventh, \"Jamque favet mundus,\"\\nthe whole of the earth, or rather its inhabitants. We meet with it again\\nin the sixty-eighth line, \"lumina mundi,\" where it seems more properly\\nto signify the visible firmament; again in the 139th, \"Et mundi struxere\\nglobum,\" it seems to refer especially to the earth, synonymous with the\\ngeneral sense of the English term <hi rend=\"ital\">world;</hi> while in the 153rd line, \"per\\ninania mundi,\" it must be supposed to mean the universe. Hyginus,\\nin his Poeticon Astronomicon, lib. i. p. 55, defines the term as follows:\\n\"Mundus appellatur is qui constat in sole et luna et terra et omnibus\\nstellis;\" and again, p. 57, \"Terra mundi media regione collocata.\" We may\\nobserve the different designations of the term <hi rend=\"ital\">mundus</hi> in <placeName key=\"tgn,1002883\">Seneca</placeName>; among\\nother passages I may refer to his Nat. Qu&aelig;st. vii. 27 &amp; iii. 30; to his\\ntreatise De Consol. &sect; 18 and De Benef. iv. 23, where I conceive the precise\\nmeanings are, respectively, the universe, the terrestrial globe, the firmament, and the heavenly bodies. The Greek term <foreign lang=\"greek\">ko/smos,</foreign> which corresponds\\nto the Latin word <hi rend=\"ital\">mundus,</hi> was likewise employed to signify, either the\\nvisible firmament or the universe. In illustration of this, it will\\nbe sufficient to refer to the treatise of Aristotle <foreign lang=\"greek\">Peri\\\\ Ko/smou,</foreign> cap. 2. p. 601. See\\nalso Stephens\\'s Thesaurus, <hi rend=\"ital\">in loco.</hi> In Apuleius\\'s treatise De Mundo,\\nwhich is a free translation of Aristotle\\'s <foreign lang=\"greek\">Peri\\\\ Ko/smou,</foreign> the term may be\\nconsidered as synonymous with universe. It is used in the same sense\\nin various parts of Apuleius\\'s writings: see Metam. ii. 23; De Deo\\nSocratis, 665, 667; De Dogmate Platonis, 574, 575, <hi rend=\"ital\">et alibi.</hi></note>, and whatever that be which we otherwise\\n\\n<pb n=\"1014\"/>\\n\\ncall the heavens<note anchored=\"yes\" place=\"foot\"><placeName key=\"tgn,2239742\">Cicero</placeName>, in his Tim&aelig;us, uses the same phraseology; \"Omne igitur\\nc&oelig;lum, sive mundus, sive quovis alio vocabulo gaudet, hoc a nobis\\nnuncupatum est,\" &sect; 2. Pomponius Mela\\'s work commences with a\\nsimilar expression; \"Omne igitur hoc, quidquid est, cui mundi c&oelig;lique\\nnomen indideris, unum id est.\" They were probably taken from a\\npassage in Plato\\'s Tim&aelig;us, \"Universum igitur hoc, C&oelig;lum, sive Mundum,\\nsive quo alio vocabulo gaudet, cognominemus,\" according to the\\ntranslation of Ficinus; Platonis Op. ix. p. 302. The word <hi rend=\"ital\">c&oelig;lum,</hi>\\nwhich is\\nemployed in the original, in its ordinary acceptation, signifies\\n<hi rend=\"ital\">the heavens,</hi>\\nthe visible firmament; as in <placeName key=\"tgn,2562922\">Ovid</placeName>, Met. i. 5, \"quod tegit omnia, c&oelig;lum.\"\\nIt is, in most cases, employed in this sense by Lucretius and by Manilius,\\nas in i. 2. of the former and in i. 14. of the latter. Occasionally, however, it is employed by both of these writers in the more general sense\\nof <hi rend=\"ital\">celestial regions,</hi> in opposition to the earth, as by Lucretius, i. 65, and\\nby Manilius, i. 352. In the line quoted by <placeName key=\"tgn,2036187\">Cicero</placeName> from Pacuvius, it\\nwould seem to mean the place in which the planets are situated; De\\nNat. Deor. ii. 91. The Greek word <foreign lang=\"greek\">ou)rano\\\\s</foreign> may be regarded as exactly\\ncorresponding to the Latin word <hi rend=\"ital\">c&oelig;lum,</hi> and employed with the same\\nmodifications; see Aristotle, De Mundo and De C&oelig;lo, and Ptolemy,\\nMag. Const. lib. i. <hi rend=\"ital\">passim;</hi> see also Stephens\\'s Thesaurus,\\n<hi rend=\"ital\">in loco.</hi> Aratus\\ngenerally uses it to designate the visible firmament, as in 1. 10, while in\\n1. 32 it means the heavenly regions. <placeName key=\"tgn,2348207\">Gesner</placeName> defines <hi rend=\"ital\">c&oelig;lum,</hi> \"Mundus\\nexclusa terra,\" and <hi rend=\"ital\">mundus,</hi> \"C&oelig;lum et quidquid cceli ambitu\\ncontinetur.\" In the passage from Plato, referred to above, the words\\nwhich\\nare translated by Ficinus <hi rend=\"ital\">c&oelig;lum</hi> and <hi rend=\"ital\">mundus,</hi> are in\\nthe original <foreign lang=\"greek\">ou)rano\\\\s</foreign>\\nand <foreign lang=\"greek\">ko/smos;</foreign> Ficinus, however, in various parts of the Tim&aelig;us, translates\\n<foreign lang=\"greek\">ou)ranbo\\\\s</foreign> by the word <hi rend=\"ital\">mundus:</hi> see t. ix. p. 306, 311, <hi rend=\"ital\">et alibi.</hi></note>, by the vault of which all things are\\nenclosed,\\n\\n<pb n=\"1015\"/>\\n\\nwe must conceive to be a Deity<note anchored=\"yes\" place=\"foot\">The following passage from <placeName key=\"tgn,2036187\">Cicero</placeName> may serve to illustrate the doctrine\\nof <placeName key=\"tgn,2119609\">Pliny</placeName>: \"Novem tibi orbibus, vel potius globis, connexa sunt omnia:\\nquorum unus est ccelestis, extimus, qui reliquos omnes complectitur,\\nsummus ipse Deus, arcens et continens c&oelig;lum;\" Som. Scip. &sect; 4. I may\\nremark, however, that the term here employed by our author is not <hi rend=\"ital\">Deus</hi>\\nbut <hi rend=\"ital\">Numen.</hi></note>, to be eternal, without bounds, neither created, nor subject, at any time, to\\ndestruction<note anchored=\"yes\" place=\"foot\">We have an interesting account of the opinions of Aristotle on this\\nsubject, in a note in M. Ajasson\\'s translation, ii. 234 <hi rend=\"ital\">et seq.,</hi> which, as\\nwell as the greater part of the notes attached to the second book of the\\nNatural History, were written by himself in conjunction with M. Marcus.</note>. To inquire what is beyond it is no concern of\\nman, nor can the human mind form any conjecture respecting\\nit. It is sacred, eternal, and without bounds, all in all; indeed including everything in itself; finite, yet like what is\\ninfinite; the most certain of all things, yet like what is uncertain, externally and internally embracing all things in\\nitself; it is the work of nature, and itself constitutes\\nnature<note anchored=\"yes\" place=\"foot\">The philosophers of antiquity were divided in their opinions respecting the great question, whether the active properties of material bodies,\\nwhich produce the phenomena of nature, are inherent in them, and\\nnecessarily attached to them, or whether they are bestowed upon them\\nby some superior power or being. The Academics and Peripatetics\\ngenerally adopted the latter opinion, the Stoics the former: <placeName key=\"tgn,2119609\">Pliny</placeName> adopts\\nthe doctrine of the Stoics; see Enfield\\'s Hist. of <placeName key=\"tgn,2578489\">Phil</placeName>. i. 229, 283, 331.</note>.</p>\\n<p>It is madness to harass the mind, as some have done, with\\nattempts to measure the world, and to publish these attempts;\\nor, like others, to argue from what they have made out,\\nthat there are innumerable other worlds, and that we must\\nbelieve there to be so many other natures, or that, if only\\none nature produced the whole, there will be so many suns\\nand so many moons, and that each of them will have immense\\ntrains of other heavenly bodies. As if the same question\\nwould not recur at every step of our inquiry, anxious as we\\nmust be to arrive at some termination; or, as if this infinity,\\nwhich we ascribe to nature, the former of all things, cannot\\nbe more easily comprehended by one single formation,\\n\\n<pb n=\"1016\"/>\\n\\nespecially when that is so extensive. It is madness, perfect\\nmadness, to go out of this world and to search for what is\\nbeyond it, as if one who is ignorant of his own dimensions\\ncould ascertain the measure of any thing else, or as if the\\nhuman mind could see what the world itself cannot contain.\\n</p></div2>\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_sects[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<milestone unit=\"para\" n=\"1\"/>\\n<p>\\n</p>\\n<p>\\nmundum et hoc quodcumque nomine alio caelum appellare libuit, cuius circumflexu degunt cuncta, numen esse credi par est, aeternum, inmensum, neque genitum neque interiturum umquam. huius extera indagare nec interest hominum nec capit humanae coniectura mentis. sacer est, aeternus, immensus, totus in toto, immo vero ipse totum, infinitus ac finito similis, omnium rerum certus et similis incerto, extra intra cuncta conplexus in se, idemque rerum naturae opus et rerum ipsa natura. furor est mensuram eius animo quosdam agitasse atque prodere ausos, alios rursus occasione hinc sumpta aut hi<hi rend=\"italics\">c</hi> data innumerabiles tradidisse mundos, ut totidem rerum naturas credi oporteret aut, si una omnes incubaret, totidem tamen\\n<pb />\\nsoles totidemque lunas et cetera etiam in uno et inmensa et innumerabilia sidera, quasi non eaedem quaestiones semper in termino cogitationi sint occursurae desiderio finis alicuius aut, si haec infinitas naturae omnium artifici possit adsignari, non idem illud in uno facilius sit intellegi, tanto praesertim opere. furor est profecto, furor egredi ex eo et, tamquam interna eius cuncta plane iam nota sint, ita scrutari extera, quasi vero mensuram ullius rei possit agere qui sui nesciat, aut me<hi rend=\"italics\">ns</hi> hominis videre quae mundus ipse non capiat. </p>\\n</div1>\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_sects[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
